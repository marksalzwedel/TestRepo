// api/clc-chat.js — CLC Chatbot with auto-discovered Markdown KB (section-selector mini-RAG)
// Runtime: Node (Vercel root functions)
const fs = require('fs/promises');
const path = require('path');

const VERSION = 'kb-v4-autoload';
const REFUSAL_LINE = 'I’m not sure how to answer that. Would you like to chat with a person?';

// ---------- AUTO-LOAD all .md files from /data ----------
const DATA_DIR = path.join(process.cwd(), 'data');

let KB_CACHE = null; // [{ name, text }]
async function loadKB() {
  if (KB_CACHE) return KB_CACHE;
  let entries = [];
  try {
    entries = await fs.readdir(DATA_DIR, { withFileTypes: true });
  } catch {
    KB_CACHE = [];
    return KB_CACHE;
  }

  const mdFiles = entries
    .filter(e => e.isFile() && /\.md$/i.test(e.name) && !e.name.startsWith('.'))
    .map(e => e.name)
    .sort((a, b) => a.localeCompare(b));

  const loaded = [];
  for (const fname of mdFiles) {
    try {
      const text = await fs.readFile(path.join(DATA_DIR, fname), 'utf8');
      const name = fname.replace(/\.md$/i, ''); // e.g., "Theology"
      loaded.push({ name, text });
    } catch {
      // skip unreadable files
    }
  }
  KB_CACHE = loaded;
  return KB_CACHE;
}

// ---------- Split Markdown into sections by headings ----------
function splitMarkdownIntoSections(md, sourceName) {
  const lines = md.split(/\r?\n/);
  const sections = [];
  let current = { title: `${sourceName}: (intro)`, body: [] };

  function pushCurrent() {
    if (current && current.body.length) {
      const text = current.body.join('\n').trim();
      if (text && text.replace(/\s+/g, '').length > 0) {
        sections.push({ source: sourceName, title: current.title, text });
      }
    }
  }

  for (const line of lines) {
    const m = line.match(/^(#{1,6})\s+(.+?)\s*$/);
    if (m) {
      pushCurrent();
      const level = m[1].length;
      const title = m[2].trim();
      current = { title: `${sourceName}: ${'#'.repeat(level)} ${title}`, body: [] };
    } else {
      current.body.push(line);
    }
  }
  pushCurrent();
  return sections;
}

// ---------- Selector scoring (no DB) ----------
const STOP = new Set([
  'the','and','or','a','an','of','to','for','in','on','at','is','are','be',
  'with','by','it','we','you','our','from','as','that','this','these','those'
]);

function tokenize(s) {
  return (s.toLowerCase().match(/[a-z0-9]+/g) || []).filter(w => !STOP.has(w));
}

function scoreSection(query, section) {
  const q = tokenize(query), t = tokenize(section.text);
  if (!q.length || !t.length) return 0;

  let overlap = 0;
  const tSet = new Set(t);
  for (const w of q) if (tSet.has(w)) overlap++;

  let titleBoost = 0;
  const titleSet = new Set(tokenize(section.title));
  for (const w of q) if (titleSet.has(w)) titleBoost += 0.5;

  const lenPenalty = Math.max(0, (t.length - 1200) / 1200); // penalize very long chunks
  return overlap + titleBoost - lenPenalty;
}

function selectTopSections(query, allSections, maxSections = 3, maxCharsTotal = 15000) {
  const scored = allSections
    .map(s => ({ s, score: scoreSection(query, s) }))
    .filter(x => x.score > 0)
    .sort((a, b) => b.score - a.score);

  const picked = [];
  let charCount = 0;
  for (const x of scored) {
    const chunk = `### ${x.s.title}\n${x.s.text}`.trim();
    if (charCount + chunk.length > maxCharsTotal) continue;
    picked.push(chunk);
    charCount += chunk.length;
    if (picked.length >= maxSections) break;
  }
  return picked;
}

// ---------- Prompts (warm tone, strict scope) ----------
const SYSTEM_PROMPT = `
You are the CLC Chatbot for Christ Lutheran Church (Eden Prairie, MN).

MISSION & SCOPE (STRICT)
• Logistics (service times, location/parking, staff, ministries, events): ONLY use christlutheran.com content and the provided “Selected Context.”
• Theology/ethics/doctrine: ONLY use WELS materials (wels.net) and Wisconsin Lutheran Seminary essays (wisluthsem.org), or clearly marked doctrine in the provided “Selected Context.”
• If the answer is not clearly supported by those sources, use the exact refusal line provided by the developer.

TONE & PASTORAL CARE
• Warm, welcoming, and kind. Plain language. Assume good intent.
• Default to concise 2–4 sentence answers. If appropriate, you may write a longer, thoughtful paragraph or a short bulleted list.
• Offer: “I can share more details if you’d like.” For sensitive topics, invite pastoral follow-up.

OPERATIONAL GUARDRAILS
• Never browse or rely on outside sources. Don’t invent details or summarize from memory.
• Benevolence/assistance: invite the person to use the contact form on christlutheran.com.
• Vendor solicitations: “Thanks for reaching out, we’re not seeking new professional services right now.”

FOOTER (always append):
"(Generated by ChatGPT; may contain occasional errors. For confirmation or pastoral care, please contact Christ Lutheran Church via christlutheran.com.)"
`.trim();

const STYLE_GUIDE = `
Style:
• Begin with a warm micro-greeting when appropriate (“Happy to help!” / “Thanks for asking.”).
• Answer directly first; then offer one optional next step (link or “would you like more details?”).
• Keep sentences short; avoid jargon; use “we” and “you” where natural.
`.trim();

const FEW_SHOT = [
  {
    role: 'system',
    content:
`Example Q: What time are services?
Example A: Happy to help! Our Sunday worship is at 9:30 AM. We’re at 16900 Main Street in Eden Prairie, and parking is on the west side. I can share more details if you’d like.`
  },
  {
    role: 'system',
    content:
`Example Q: Do you offer Sunday School?
Example A: Yes! Sunday School meets at 10:35 AM following worship during the school year. If you’re bringing kids, I can share check-in details.`
  }
];

// ---------- HTTP handler ----------
module.exports = async function handler(req, res) {
  // GET health/version + file list
  if (req.method === 'GET') {
    const kb = await loadKB();
    const sizes = Object.fromEntries(kb.map(k => [k.name, k.text.length]));
    return res.status(200).json({
      ok: true,
      version: VERSION,
      hasKey: Boolean(process.env.OPENAI_API_KEY),
      files: kb.map(k => k.name),
      sizes,
      node: process.version
    });
  }

  if (req.method !== 'POST') return res.status(405).send('Method Not Allowed');

  // Parse JSON body
  let raw = '';
  await new Promise(resolve => { req.on('data', c => (raw += c)); req.on('end', resolve); });
  let text = '';
  try {
    const json = raw ? JSON.parse(raw) : (req.body || {});
    text = typeof json.text === 'string' ? json.text : '';
  } catch {
    return res.status(400).json({ error: 'Invalid JSON', version: VERSION });
  }
  if (!text) return res.status(400).json({ error: 'Missing text', version: VERSION });

  // Load KB and split into sections (across ALL .md files)
  const kb = await loadKB();
  const allSections = kb.flatMap(k => splitMarkdownIntoSections(k.text, k.name));

  // Select the most relevant sections
  const picked = selectTopSections(text, allSections, /*maxSections*/ 3, /*maxCharsTotal*/ 15000);
  const pickedTitles = picked.map(s => s.split('\n')[0].replace(/^###\s*/, ''));

  const selectedContext = picked.length
    ? `SELECTED CONTEXT (top ${picked.length} sections):\n\n${picked.join('\n\n---\n\n')}`
    : `SELECTED CONTEXT: (none matched closely)`;

  const messages = [
    { role: 'system', content: SYSTEM_PROMPT },
    { role: 'system', content: STYLE_GUIDE },
    ...FEW_SHOT,
    { role: 'system', content: `Use this exact refusal line when needed:\n${REFUSAL_LINE}` },
    { role: 'system', content: 'If sources/context are insufficient, use the refusal line verbatim. Do not improvise.' },
    { role: 'system', content: selectedContext },
    { role: 'user', content: text }
  ];

  try {
    if (!process.env.OPENAI_API_KEY) {
      return res.status(500).json({ error: 'OPENAI_API_KEY is not set', version: VERSION });
    }

    const aiRes = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        temperature: 0.35,
        messages
      })
    });

    const textBody = await aiRes.text();
    if (!aiRes.ok) {
      return res.status(502).json({
        error: 'OpenAI error',
        status: aiRes.status,
        statusText: aiRes.statusText,
        body: textBody.slice(0, 1200),
        version: VERSION
      });
    }

    let data;
    try { data = JSON.parse(textBody); }
    catch {
      return res.status(500).json({ error: 'Failed to parse OpenAI JSON', body: textBody.slice(0, 1200), version: VERSION });
    }

    const reply = data?.choices?.[0]?.message?.content?.trim() || REFUSAL_LINE;
    const handoff = new RegExp(REFUSAL_LINE.replace(/[.*+?^${}()|[\]\\]/g, '\\$&'), 'i').test(reply);

    return res.status(200).json({
      reply,
      handoff,
      version: VERSION,
      contextSectionsUsed: picked.length,
      pickedTitles
    });
  } catch (e) {
    return res.status(500).json({ error: 'Server error', details: String(e), version: VERSION });
  }
};
