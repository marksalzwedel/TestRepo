// api/clc-chat.js — CLC Chatbot with local KB context (Markdown)
// Runtime: Node (Vercel root functions)
const fs = require('fs/promises');
const path = require('path');

const VERSION = 'kb-v1';
const KB_PATH = path.join(process.cwd(), 'data', 'ClcInfo.md');

// Simple in-memory cache so we only read the file once per lambda boot
let KB_CACHE = null;
async function loadKB() {
  if (KB_CACHE !== null) return KB_CACHE;
  try {
    const raw = await fs.readFile(KB_PATH, 'utf8');
    // Optional: trim overly large files (safety)
    const maxChars = 60_000; // ~10-12k tokens rough order; adjust if needed
    KB_CACHE = raw.length > maxChars ? raw.slice(0, maxChars) : raw;
  } catch (e) {
    // If file missing, keep null so health shows hasKB: false
    KB_CACHE = null;
  }
  return KB_CACHE;
}

const SYSTEM_PROMPT = `
You are the CLC Chatbot for Christ Lutheran Church (Eden Prairie, MN).

MISSION & SCOPE (STRICT)
• Logistics (service times, location/parking, staff, ministries, events): ONLY use christlutheran.com content and the provided “Context” below.
• Theology/ethics/doctrine: ONLY use WELS materials (wels.net) and Wisconsin Lutheran Seminary essays (wisluthsem.org), or clearly marked doctrine in the provided “Context.”
• If the answer is not clearly supported by those sources, reply EXACTLY:
"That sounds like a question that would be better addressed by a human. Would you care to chat with our Pastor or one of our staff?"

TONE & PASTORAL CARE
• Warm, friendly, and kind—be welcoming and brief by default. Offer to provide a little more detail if the person would like.
• Avoid partisan politics; handle sensitive topics gently. Offer the church office or Pastor Olson as needed.

OPERATIONAL GUARDRAILS
• Never browse or rely on outside sources. Do not invent details or summarize from memory.
• Benevolence/assistance: Invite the person to use the contact form on christlutheran.com so a staff member can follow up.
• Vendor solicitations: “Thanks for reaching out, we’re not seeking new professional services right now.”

FOOTER (always append):
"(Generated by ChatGPT; may contain occasional errors. For confirmation or pastoral care, please contact Christ Lutheran Church via christlutheran.com.)"
`.trim();

module.exports = async function handler(req, res) {
  // GET = health/version check (also shows KB status)
  if (req.method === 'GET') {
    const kb = await loadKB();
    return res.status(200).json({
      ok: true,
      version: VERSION,
      hasKey: Boolean(process.env.OPENAI_API_KEY),
      hasKB: Boolean(kb),
      kbBytes: kb ? kb.length : 0,
      node: process.version
    });
  }

  if (req.method !== 'POST') {
    return res.status(405).send('Method Not Allowed');
  }

  // Robust body parsing (handles cases where req.body isn't pre-parsed)
  let raw = '';
  await new Promise((resolve) => {
    req.on('data', (c) => (raw += c));
    req.on('end', resolve);
  });

  let text = '';
  try {
    const json = raw ? JSON.parse(raw) : (req.body || {});
    text = typeof json.text === 'string' ? json.text : '';
  } catch {
    return res.status(400).json({ error: 'Invalid JSON', version: VERSION });
  }
  if (!text) return res.status(400).json({ error: 'Missing text', version: VERSION });

  // Load local knowledge base
  const kb = await loadKB();

  // Build the message list with KB context (if present)
  // Keep context concise; the model should prioritize it.
  const messages = [
    { role: 'system', content: SYSTEM_PROMPT },
    ...(kb ? [{
      role: 'system',
      content:
        "CONTEXT (from data/ClcInfo.md — approved congregation info):\n" +
        kb +
        "\n\nUse ONLY this context for logistics, and ONLY WELS/WSL sources for doctrine. If the context does not contain the answer, use the refusal line."
    }] : []),
    { role: 'system', content: 'If sources/context are insufficient, use the refusal line verbatim. Do not improvise.' },
    { role: 'user', content: text }
  ];

  try {
    // Safety: check env var early
    if (!process.env.OPENAI_API_KEY) {
      return res.status(500).json({ error: 'OPENAI_API_KEY is not set', version: VERSION });
    }

    const aiRes = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        temperature: 0.2,
        messages
      })
    });

    const textBody = await aiRes.text();
    if (!aiRes.ok) {
      // Surface upstream error in JSON for easy debugging
      return res.status(502).json({
        error: 'OpenAI error',
        status: aiRes.status,
        statusText: aiRes.statusText,
        body: textBody.slice(0, 1200),
        version: VERSION
      });
    }

    let data;
    try { data = JSON.parse(textBody); }
    catch {
      return res.status(500).json({ error: 'Failed to parse OpenAI JSON', body: textBody.slice(0, 1200), version: VERSION });
    }

    const reply =
      data?.choices?.[0]?.message?.content?.trim() ||
      'I’m not certain based on our sources. Would you like to chat with a person?';

    const handoff = /i’m not certain based on our sources/i.test(reply);

    return res.status(200).json({ reply, handoff, version: VERSION, usedKB: Boolean(kb) });
  } catch (e) {
    return res.status(500).json({ error: 'Server error', details: String(e), version: VERSION });
  }
};
